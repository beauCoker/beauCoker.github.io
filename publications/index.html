<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Beau Coker</title> <meta name="author" content="Beau Coker"/> <meta name="description" content="About Beau "/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¥”</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://beaucoker.github.io/publications/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">BeauÂ </span>Coker</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <p>One day I hope I can describe my publications like <a href="https://youtu.be/c2MEZg1Qol4" target="_blank" rel="noopener noreferrer">Morbo describes his children</a> (sound on). Until then, this is what I have.</p> <div class="publications"> <h2 class="year">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/ibvi.png"></div> <div id="ibvi_2025" class="col-sm-8"> <div class="title">Variational Deep Learning via Implicit Regularization</div> <div class="author"> <a href="https://jonathanwenger.github.io" target="_blank" rel="noopener noreferrer">Jonathan Wenger</a>,Â <em>Beau Coker</em>,Â Juraj Marusic,Â andÂ <a href="https://sites.stat.columbia.edu/cunningham/" target="_blank" rel="noopener noreferrer">John P. Cunningham</a> </div> <div class="periodical"> <em>In Pending review</em> 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2505.20235" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Modern deep learning models generalize remarkably well in-distribution, despite being overparametrized and trained with little to no \emphexplicit regularization. Instead, current theory credits \emphimplicit regularization imposed by the choice of architecture, hyperparameters and optimization procedure. However, deploying deep learning models out-of-distribution, in sequential decision-making tasks, or in safety-critical domains, necessitates reliable uncertainty quantification, not just a point estimate. The machinery of modern approximate inference â€” Bayesian deep learning â€” should answer the need for uncertainty quantification, but its effectiveness has been challenged by our inability to define useful \emphexplicit inductive biases through priors, as well as the associated computational burden. Instead, in this work we demonstrate, both theoretically and empirically, how to regularize a variational deep network \emphimplicitly via the optimization procedure, just as for standard deep learning. We fully characterize the inductive bias of (stochastic) gradient descent in the case of an overparametrized linear model as generalized variational inference and demonstrate the importance of the choice of parametrization. Finally, we show empirically that our approach achieves strong in- and out-of-distribution performance without tuning of additional hyperparameters and with minimal time and memory overhead over standard deep learning.</p> </div> </div> </div> </li></ol> <h2 class="year">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/gp_mismatch.png"></div> <div id="coker_icml2023" class="col-sm-8"> <div class="title">Implications of Gaussian process kernel mismatch for out-of-distribution data</div> <div class="author"> <em>Beau Coker</em>,Â andÂ <a href="https://finale.seas.harvard.edu" target="_blank" rel="noopener noreferrer">Finale Doshi-Velez</a> </div> <div class="periodical"> <em>In ICML workshops Spurious correlations, Invariance, and Stability (SCIS) and Structured Probabilistic Inference and Generative Modeling (SPIGM)</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/pdf?id=AoJUCbkLWP" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Gaussian processes provide reliable uncertainty estimates in nonlinear modeling, but a poor choice of the kernel can lead to poor generalization. Although learning the hyperparameters of the kernel typically leads to optimal generalization on in-distribution test data, we demonstrate issues with out-of-distribution test data. We then investigate three potential solutionsâ€“ (1) learning the smoothness using a discrete cosine transform, (2) assuming fatter tails in function-space using a Student-t process, and (3) learning a more flexible kernel using deep kernel learningâ€“and find some evidence in favor of the first two.</p> </div> </div> </div> </li></ol> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/finite_bnns.png"></div> <div id="yao_gps2022" class="col-sm-8"> <div class="title">An Empirical Analysis of the Advantages of Finite v.s.Â Infinite Width Bayesian Neural Networks</div> <div class="author"> <a href="https://yaojiayu0826.github.io" target="_blank" rel="noopener noreferrer">Jiayu Yao</a>,Â <a href="https://yanivyacoby.github.io" target="_blank" rel="noopener noreferrer">Yaniv Yacoby</a>,Â <em>Beau Coker</em>,Â <a href="https://onefishy.github.io" target="_blank" rel="noopener noreferrer">Weiwei Pan</a>,Â andÂ <a href="https://finale.seas.harvard.edu" target="_blank" rel="noopener noreferrer">Finale Doshi-Velez</a> </div> <div class="periodical"> <em>In NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2211.09184" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Comparing Bayesian neural networks (BNNs) with different widths is challenging because, as the width increases, multiple model properties change simultaneously, and, inference in the finite-width case is intractable. In this work, we empirically compare finite- and infinite-width BNNs, and provide quantitative and qualitative explanations for their performance difference. We find that when the model is mis-specified, increasing width can hurt BNN performance. In these cases, we provide evidence that finite-width BNNs generalize better partially due to the properties of their frequency spectrum that allows them to adapt under model mismatch.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/fdt.png"></div> <div id="coker_neurips2022" class="col-sm-8"> <div class="title">Towards a Unified Framework for Uncertainty-aware Nonlinear Variable Importance Estimation with Theoretical Guarantees</div> <div class="author"> <a href="https://www.linkedin.com/in/wenying-deng-0a9911179/" target="_blank" rel="noopener noreferrer">Wenying Deng</a>,Â <em>Beau Coker</em>,Â <a href="https://scholar.harvard.edu/rajarshi/home" target="_blank" rel="noopener noreferrer">Rajarshi Mukherjee</a>,Â <a href="http://jereliu.info" target="_blank" rel="noopener noreferrer">Jeremiah Zhe Liu</a>,Â andÂ <a href="https://www.hsph.harvard.edu/brent-coull/" target="_blank" rel="noopener noreferrer">Brent A. Coull</a> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS)</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2204.07293.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>We develop a simple and unified framework for nonlinear variable importance estimation that incorporates uncertainty in the prediction function and is compatible with a wide range of machine learning models (e.g., tree ensembles, kernel methods, neural networks, etc). In particular, for a learned nonlinear model f(\mathbfx), we consider quantifying the importance of an input variable \mathbfx^j using the integrated partial derivative \Psi_j = \Vert \fracâˆ‚âˆ‚\mathbfx^j f(\mathbfx)\Vert^2_P_\mathcalX. We then (1) provide a principled approach for quantifying uncertainty in variable importance by deriving its posterior distribution, and (2) show that the approach is generalizable even to non-differentiable models such as tree ensembles. Rigorous Bayesian nonparametric theorems are derived to guarantee the posterior consistency and asymptotic uncertainty of the proposed approach. Extensive simulations and experiments on healthcare benchmark datasets confirm that the proposed algorithm outperforms existing classic and recent variable selection methods. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">coker_neurips2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards a Unified Framework for Uncertainty-aware Nonlinear Variable Importance Estimation with Theoretical Guarantees}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems (NeurIPS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Deng, Wenying and Coker, Beau and Mukherjee, Rajarshi and Liu, Jeremiah Zhe and Coull, Brent A.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/wide_bnns.png"></div> <div id="coker_aistats2022" class="col-sm-8"> <div class="title">Wide Mean-Field Variational Bayesian Neural Networks Ignore the Data</div> <div class="author"> <em>Beau Coker</em>,Â <a href="https://wesselb.github.io/about" target="_blank" rel="noopener noreferrer">Wessel P. Bruinsma</a>,Â <a href="https://davidrburt.github.io" target="_blank" rel="noopener noreferrer">David R. Burt</a>,Â <a href="https://onefishy.github.io" target="_blank" rel="noopener noreferrer">Weiwei Pan</a>,Â andÂ <a href="https://finale.seas.harvard.edu" target="_blank" rel="noopener noreferrer">Finale Doshi-Velez</a> </div> <div class="periodical"> <em>In Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2202.11670.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Bayesian neural networks (BNNs) combine the expressive power of deep learning with the advantages of Bayesian formalism. In recent years, the analysis of wide, deep BNNs has provided theoretical insight into their priors and posteriors. However, we have no analogous insight into their posteriors under approximate inference. In this work, we show that mean-field variational inference entirely fails to model the data when the network width is large and the activation function is odd. Specifically, for fully-connected BNNs with odd activation functions and a homoscedastic Gaussian likelihood, we show that the optimal mean-field variational posterior predictive (i.e., function space) distribution converges to the prior predictive distribution as the width tends to infinity. We generalize aspects of this result to other likelihoods. Our theoretical results are suggestive of underfitting behavior previously observered in BNNs. While our convergence bounds are non-asymptotic and constants in our analysis can be computed, they are currently too loose to be applicable in standard training regimes. Finally, we show that the optimal approximate posterior need not tend to the prior if the activation function is not odd, showing that our statements cannot be generalized arbitrarily.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">coker_aistats2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Wide Mean-Field Variational Bayesian Neural Networks Ignore the Data}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Coker, Beau and Bruinsma, Wessel P. and Burt, David R. and Pan, Weiwei and Doshi-Velez, Finale}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/wide_bnns_workshop.png"></div> <div id="coker_udl2021" class="col-sm-8"> <div class="title">Wide Mean-Field Variational Bayesian Neural Networks Ignore the Data</div> <div class="author"> <em>Beau Coker</em>,Â <a href="https://onefishy.github.io" target="_blank" rel="noopener noreferrer">Weiwei Pan</a>,Â andÂ <a href="https://finale.seas.harvard.edu" target="_blank" rel="noopener noreferrer">Finale Doshi-Velez</a> </div> <div class="periodical"> <em>In ICML Workshop on Uncertainty and Robustness in Deep Learning</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2106.07052.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Variational inference enables approximate posterior inference of the highly over-parameterized neural networks that are popular in modern machine learning. Unfortunately, such posteriors are known to exhibit various pathological behaviors. We prove that as the number of hidden units in a single-layer Bayesian neural network tends to infinity, the function-space posterior mean under mean-field variational inference actually converges to zero, completely ignoring the data (assuming it has been centered around zero). This is in contrast to the true posterior, which converges to a Gaussian process. Our work provides insight into the over-regularization of the KL divergence in variational inference.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">coker_udl2021</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Wide Mean-Field Variational Bayesian Neural Networks Ignore the Data}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICML Workshop on Uncertainty and Robustness in Deep Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Coker, Beau and Pan, Weiwei and Doshi-Velez, Finale}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/hacking.png"></div> <div id="coker_ms2018" class="col-sm-8"> <div class="title">A Theory of Statistical Inference for Ensuring the Robustness of Scientific Results</div> <div class="author"> <em>Beau Coker</em>,Â <a href="https://users.cs.duke.edu/~cynthia/" target="_blank" rel="noopener noreferrer">Cynthia Rudin</a>,Â andÂ <a href="https://gking.harvard.edu" target="_blank" rel="noopener noreferrer">Gary King</a> </div> <div class="periodical"> <em>Management Science</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://pubsonline.informs.org/doi/10.1287/mnsc.2020.3818" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/1804.08646.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Inference is the process of using facts we know to learn about facts we do not know. A theory of inference gives assumptions necessary to get from the former to the latter, along with a definition for and summary of the resulting uncertainty. Any one theory of inference is neither right nor wrong, but merely an axiom that may or may not be useful. Each of the many diverse theories of inference can be valuable for certain applications. However, no existing theory of inference addresses the tendency to choose, from the range of plausible data analysis specifications consistent with prior evidence, those that inadvertently favor oneâ€™s own hypotheses. Since the biases from these choices are a growing concern across scientific fields, and in a sense the reason the scientific community was invented in the first place, we introduce a new theory of inference designed to address this critical problem. We introduce hacking intervals, which are the range of a summary statistic one may obtain given a class of possible endogenous manipulations of the data. Hacking intervals require no appeal to hypothetical data sets drawn from imaginary superpopulations. A scientific result with a small hacking interval is more robust to researcher manipulation than one with a larger interval, and is often easier to interpret than a classical confidence interval. Some versions of hacking intervals turn out to be equivalent to classical confidence intervals, which means they may also provide a more intuitive and potentially more useful interpretation of classical confidence intervals.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">coker_ms2018</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Coker, Beau and Rudin, Cynthia and King, Gary}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{67}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Theory of Statistical Inference for Ensuring the Robustness of Scientific Results}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Management Science}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1287/mnsc.2020.3818}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/porbnet.png"></div> <div id="coker_uai2020" class="col-sm-8"> <div class="title">PoRB-Nets: Poisson Process Radial Basis Function Networks</div> <div class="author"> <em>Beau Coker</em>,Â <a href="https://melaniefp.github.io" target="_blank" rel="noopener noreferrer">Melanie Pradier</a>,Â andÂ <a href="https://finale.seas.harvard.edu" target="_blank" rel="noopener noreferrer">Finale Doshi-Velez</a> </div> <div class="periodical"> <em>In Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI)</em> 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://proceedings.mlr.press/v124/coker20a/coker20a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Bayesian neural networks (BNNs) are flexible function priors well-suited to situations in which data are scarce and uncertainty must be quantified. Yet, common weight priors are able to encode little functional knowledge and can behave in undesirable ways. We present a novel prior over radial basis function networks (RBFNs) that allows for independent specification of functional amplitude variance and lengthscale (i.e., smoothness), where the inverse lengthscale corresponds to the concentration of radial basis functions. When the lengthscale is uniform over the input space, we prove consistency and approximate variance stationarity. This is in contrast to common BNN priors, which are highly nonstationary. When the input dependence of the lengthscale is unknown, we show how it can be inferred. We compare this modelâ€™s behavior to standard BNNs and Gaussian processes using synthetic and real examples.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">coker_uai2020</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PoRB-Nets: Poisson Process Radial Basis Function Networks}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI)}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{124}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1338--1347}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Coker, Beau and Pradier, Melanie and Doshi-Velez, Finale}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/compas.png"></div> <div id="rudin_hdsr2020" class="col-sm-8"> <div class="title">The Age of Secrecy and Unfairness in Recidivism Prediction</div> <div class="author"> <a href="https://users.cs.duke.edu/~cynthia/" target="_blank" rel="noopener noreferrer">Cynthia Rudin</a>,Â <a href="https://carolinewang01.github.io" target="_blank" rel="noopener noreferrer">Caroline Wang</a>,Â andÂ <em>Beau Coker</em> </div> <div class="periodical"> <em>Harvard Data Science Review</em> Mar 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hdsr.mitpress.mit.edu/pub/7z10o269" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>In our current society, secret algorithms make important decisions about individuals. There has been substantial discussion about whether these algorithms are unfair to groups of individuals. While noble, this pursuit is complex and ultimately stagnating because there is no clear definition of fairness and competing definitions are largely incompatible. We argue that the focus on the question of fairness is misplaced, as these algorithms fail to meet a more important and yet readily obtainable goal: transparency. As a result, creators of secret algorithms can provide incomplete or misleading descriptions about how their models work, and various other kinds of errors can easily go unnoticed. By trying to partially reconstruct the COMPAS modelâ€”a recidivism risk-scoring model used throughout the criminal justice systemâ€”we show that it does not seem to depend linearly on the defendantâ€™s age, despite statements to the contrary by the modelâ€™s creator. This observation has not been made before despite many recently published papers on COMPAS. Furthermore, by subtracting from COMPAS its (hypothesized) nonlinear age component, we show that COMPAS does not necessarily depend on race other than through age and criminal history. This contradicts ProPublicaâ€™s analysis, which made assumptions about age that disagree with what we observe in the data. In other words, faulty assumptions about a proprietary model led to faulty conclusions that went unchecked until now. Were the model transparent in the first place, this likely would not have occurred. We demonstrate other issues with definitions of fairness and lack of transparency in the context of COMPAS, including that a simple model based entirely on a defendantâ€™s age is as â€˜unfairâ€™ as COMPAS by ProPublicaâ€™s chosen definition. We find that there are many defendants with low risk scores but long criminal histories, suggesting that data inconsistencies occur frequently in criminal justice databases. We argue that transparency satisfies a different notion of procedural fairness by providing both the defendants and the public with the opportunity to scrutinize the methodology and calculations behind risk scores for recidivism.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">rudin_hdsr2020</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Harvard Data Science Review}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1162/99608f92.6ed64b30}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{https://hdsr.mitpress.mit.edu/pub/7z10o269}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Age of Secrecy and Unfairness in Recidivism Prediction}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hdsr.mitpress.mit.edu/pub/7z10o269}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rudin, Cynthia and Wang, Caroline and Coker, Beau}</span><span class="p">,</span>
  <span class="na">date</span> <span class="p">=</span> <span class="s">{2020-03-31}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">day</span> <span class="p">=</span> <span class="s">{31}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/latent.png"></div> <div id="kompa_psb2020" class="col-sm-8"> <div class="title">Learning a Latent Space of Highly Multidimensional Cancer Data</div> <div class="author"> Benjamin Kompa,Â andÂ <em>Beau Coker</em> </div> <div class="periodical"> <em>In Biocomputing</em> Mar 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.worldscientific.com/doi/abs/10.1142/9789811215636_0034" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>We introduce a Unified Disentanglement Network (UFDN) trained on The Cancer Genome Atlas (TCGA), which we refer to as UFDN-TCGA. We demonstrate that UFDN-TCGA learns a biologically relevant, low-dimensional latent space of high-dimensional gene expression data by applying our network to two classification tasks of cancer status and cancer type. UFDN-TCGA performs comparably to random forest methods. The UFDN allows for continuous, partial interpolation between distinct cancer types. Furthermore, we perform an analysis of differentially expressed genes between skin cutaneous melanoma (SKCM) samples and the same samples interpolated into glioblastoma (GBM). We demonstrate that our interpolations consist of relevant metagenes that recapitulate known glioblastoma mechanisms.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kompa_psb2020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kompa, Benjamin and Coker, Beau}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning a Latent Space of Highly Multidimensional Cancer Data}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Biocomputing}</span><span class="p">,</span>
  <span class="na">chapter</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{379-390}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1142/9789811215636_0034}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2025 Beau Coker. Help! I'm trapped in a footnote! </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-214939069-1"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-214939069-1");</script> </body> </html>